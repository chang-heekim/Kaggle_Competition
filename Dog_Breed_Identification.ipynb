{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dog Breed Identification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1wf5L6YmYuyOIO0lu_C3ioww21P_OmbcW",
      "authorship_tag": "ABX9TyN5T5CX46YwyX3BI+iW+73V"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7gBV0Zkdvjv"
      },
      "outputs": [],
      "source": [
        "!unzip /content/drive/MyDrive/dataset/dog-breed-identification.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm"
      ],
      "metadata": {
        "id": "txGWQtO0wHoy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8d91f68-080f-4bb0-f3a2-90068e082788"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting timm\n",
            "  Downloading timm-0.6.5-py3-none-any.whl (512 kB)\n",
            "\u001b[K     |████████████████████████████████| 512 kB 9.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.11.0+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.12.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (4.1.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.21.6)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (1.24.3)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.6.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os \n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch.transforms import ToTensor\n",
        "from sklearn.model_selection import KFold\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from tqdm import tqdm\n",
        "import torch.nn.functional as F\n",
        "import timm"
      ],
      "metadata": {
        "id": "IPW1axTnHEyH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('save_models/', exist_ok=True)\n",
        "\n",
        "n_classes = 120\n",
        "IMG_SIZE = 256\n",
        "seed = 1024\n",
        "batch_size = 128\n",
        "epochs = 5\n",
        "lr = 1e-3\n",
        "weight_decay = 0.1\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "VaJJ54DXm2Wf"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, img_paths, labels=None, mode='train', IMG_SIZE=256):\n",
        "        super(CustomDataset, self).__init__()\n",
        "\n",
        "        self.img_paths = img_paths\n",
        "        self.labels = labels\n",
        "        self.mode = mode\n",
        "        self.train_transform = A.Compose([\n",
        "            A.Resize(IMG_SIZE, IMG_SIZE),                      \n",
        "            A.RandomCrop(224, 224),\n",
        "            A.GaussNoise(p=0.5),\n",
        "            A.OneOf([\n",
        "                A.HorizontalFlip(p=1),\n",
        "                A.Rotate(p=1)       \n",
        "            ], p=0.5),\n",
        "            A.OneOf([\n",
        "                A.GridDistortion(always_apply=False, p=1),\n",
        "                A.OpticalDistortion(distort_limit=2, shift_limit=0.5, p=1),\n",
        "            ], p=0.5),\n",
        "            A.RandomBrightnessContrast(p=0.3),\n",
        "            ToTensor(normalize={'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}),\n",
        "        ])\n",
        "        \n",
        "        self.test_transform = A.Compose([\n",
        "            A.Resize(IMG_SIZE, IMG_SIZE), \n",
        "            ToTensor(normalize={'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}),\n",
        "        ])\n",
        "                                         \n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.img_paths[idx]\n",
        "        \n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        if self.mode == 'train':\n",
        "            augmented  = self.train_transform(image=image)\n",
        "            image = augmented['image']\n",
        "        else:\n",
        "            augmented = self.test_transform(image=image)\n",
        "            image = augmented['image']\n",
        "\n",
        "        if self.mode == 'train' or self.mode == 'valid' or self.mode.startswith('augment'):\n",
        "            label = self.labels[idx]\n",
        "            return image, torch.tensor(label)\n",
        "        elif self.mode == 'test':\n",
        "            return image\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, n_classes):\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        self.model = timm.create_model('efficientnet_b3', pretrained=True, num_classes=n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        return x\n",
        "        \n",
        "\n",
        "\n",
        "def get_accuracy(output, label):\n",
        "    output = output.to(\"cpu\")\n",
        "    label = label.to(\"cpu\")\n",
        "\n",
        "    sm = F.softmax(output, dim=1)\n",
        "    _, index = torch.max(sm, dim=1)\n",
        "    return torch.sum((label == index)) / label.size()[0]"
      ],
      "metadata": {
        "id": "2cBb85LBMR1b"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_image_paths = glob('train/*.jpg')\n",
        "test_image_paths = glob('test/*.jpg')\n",
        "\n",
        "print(len(train_image_paths), len(test_image_paths))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NH7w5i9hgs1W",
        "outputId": "9e1356b5-801d-47ff-f750-20c75ae4f15d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10222 10357\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels_df = pd.read_csv('labels.csv')\n",
        "classes = np.unique(labels_df.breed.values)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels = label_encoder.fit_transform(labels_df['breed'])\n",
        "\n",
        "print(f'number of classes: {len(classes)}     number of labels: {len(train_labels)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBqawZCqHNLc",
        "outputId": "bbaa64e8-44c7-4f23-a6a0-17e8ac4c457a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of classes: 120     number of labels: 10222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(3):\n",
        "    train_image_paths += train_image_paths\n",
        "    train_labels = np.concatenate([train_labels, train_labels], 0)\n",
        "\n",
        "print(len(train_image_paths), len(train_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALG4AJ0yz2qo",
        "outputId": "7b23b830-e321-4308-c8ce-d93fff58f0b9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "81776 81776\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
        "\n",
        "best_model_epoch = []\n",
        "models = []\n",
        "fold_train_losses = []\n",
        "fold_val_losses = []\n",
        "fold_train_acc = []\n",
        "fold_val_acc = []\n",
        "\n",
        "for idx, (train_idx, val_idx) in enumerate(kfold.split(train_image_paths, train_labels)):\n",
        "    print(f'---------- KFold[{idx + 1}/5] ----------')\n",
        "    fold_image_paths = [train_image_paths[i] for i in train_idx]\n",
        "    fold_labels = [train_labels[i] for i in train_idx]\n",
        "    fold_train_dataset = CustomDataset(fold_image_paths, fold_labels, mode='train')\n",
        "\n",
        "    fold_val_image_paths = [train_image_paths[i] for i in val_idx]\n",
        "    fold_val_labels = [train_labels[i] for i in val_idx]\n",
        "    fold_val_dataset = CustomDataset(fold_val_image_paths, fold_val_labels, mode='valid')\n",
        "\n",
        "    train_loader = DataLoader(fold_train_dataset, shuffle=True, batch_size=batch_size)\n",
        "    valid_loader = DataLoader(fold_val_dataset, batch_size=batch_size)\n",
        "\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    model = Model(n_classes).to(device)\n",
        "\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100, eta_min=0.001)\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    best_val_loss = np.inf\n",
        "    stop = 0\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_accs = []\n",
        "    val_accs = []\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        train_acc = 0\n",
        "        for batch_idx, (imgs, labels) in enumerate(train_loader):\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            with torch.cuda.amp.autocast():\n",
        "                outputs = model(imgs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            train_loss += loss.item() \n",
        "            train_acc += torch.sum(preds == labels.data) / outputs.shape[0]\n",
        "\n",
        "        scheduler.step()\n",
        "        train_epoch_loss = train_loss / len(train_loader)\n",
        "        train_epoch_acc = train_acc / len(train_loader)\n",
        "\n",
        "        train_losses.append(train_epoch_loss)\n",
        "        train_accs.append(train_epoch_acc)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            val_loss = 0\n",
        "            val_acc = 0\n",
        "            model.eval()\n",
        "            for val_idx, (val_imgs, val_labels) in enumerate(valid_loader):\n",
        "                val_imgs, val_labels = val_imgs.to(device), val_labels.to(device)\n",
        "\n",
        "                with torch.cuda.amp.autocast():\n",
        "                    val_outputs = model(val_imgs)\n",
        "                _, val_preds = torch.max(val_outputs, 1)\n",
        "                loss = criterion(val_outputs, val_labels)\n",
        "\n",
        "                val_loss += loss.item()\n",
        "                val_acc += torch.sum(val_preds == val_labels.data) / val_outputs.shape[0]\n",
        "\n",
        "            val_epoch_loss = val_loss / len(valid_loader)\n",
        "            val_epoch_acc = val_acc / len(valid_loader)\n",
        "\n",
        "            val_losses.append(val_epoch_loss)\n",
        "            val_accs.append(val_epoch_acc)\n",
        "\n",
        "            if val_loss < best_val_loss:\n",
        "                stop = 0\n",
        "                best_val_loss = val_loss\n",
        "                path = f'save_models/best_model_{idx + 1}fold_epoch-{epoch}.pth'\n",
        "                torch.save(model.state_dict(), path)\n",
        "                print('      ** Save Model **')\n",
        "                best_model_epoch.append(path)\n",
        "            else:\n",
        "                stop += 1\n",
        "            \n",
        "            if stop == 3:\n",
        "                end_time = time.time() - start_time\n",
        "                print(f'[Epoch {epoch}/{epochs}] [elapsed time: {end_time}]')\n",
        "                print(f'[Train Loss: {train_epoch_loss}] [Train Accuracy: {train_epoch_acc}]')\n",
        "                print(f'[Validation Loss: {val_epoch_loss}] [Validation Accuracy: {val_epoch_acc}]')\n",
        "                print('     ** Early Stop **')\n",
        "                models.append(best_model_epoch.pop(-1))\n",
        "                break\n",
        "\n",
        "            end_time = time.time() - start_time\n",
        "            print(f'[Epoch {epoch}/{epochs}] [elapsed time: {end_time}]')\n",
        "            print(f'[Train Loss: {train_epoch_loss}] [Train Accuracy: {train_epoch_acc}]')\n",
        "            print(f'[Validation Loss: {val_epoch_loss}] [Validation Accuracy: {val_epoch_acc}]')\n",
        "            print(f'Early Stop Count: {stop}')\n",
        "            print()\n",
        "\n",
        "    models.append(best_model_epoch.pop(-1))\n",
        "\n",
        "    fold_train_losses.append(train_losses)\n",
        "    fold_val_losses.append(val_losses)\n",
        "    fold_train_acc.append(train_acc)\n",
        "    fold_val_acc.append(val_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7enjPtne7lvl",
        "outputId": "b65e64a4-bdf9-4ece-dcda-e84f884e95f8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------- KFold[1/5] ----------\n",
            "      ** Save Model **\n",
            "[Epoch 1/5] [elapsed time: 1097.830216884613]\n",
            "[Train Loss: 3.5450191497802734] [Train Accuracy: 0.328643798828125]\n",
            "[Validation Loss: 1.7888870239257812] [Validation Accuracy: 0.7785449028015137]\n",
            "Early Stop Count: 0\n",
            "\n",
            "      ** Save Model **\n",
            "[Epoch 2/5] [elapsed time: 2195.3119213581085]\n",
            "[Train Loss: 1.4551982879638672] [Train Accuracy: 0.8723602294921875]\n",
            "[Validation Loss: 1.103302001953125] [Validation Accuracy: 0.9772704839706421]\n",
            "Early Stop Count: 0\n",
            "\n",
            "      ** Save Model **\n",
            "[Epoch 3/5] [elapsed time: 3292.563585996628]\n",
            "[Train Loss: 1.1549186706542969] [Train Accuracy: 0.9568125605583191]\n",
            "[Validation Loss: 1.0277595520019531] [Validation Accuracy: 0.9896166920661926]\n",
            "Early Stop Count: 0\n",
            "\n",
            "      ** Save Model **\n",
            "[Epoch 4/5] [elapsed time: 4389.540983915329]\n",
            "[Train Loss: 1.1019906997680664] [Train Accuracy: 0.96875]\n",
            "[Validation Loss: 1.0091171264648438] [Validation Accuracy: 0.9910107254981995]\n",
            "Early Stop Count: 0\n",
            "\n",
            "      ** Save Model **\n",
            "[Epoch 5/5] [elapsed time: 5486.0189917087555]\n",
            "[Train Loss: 1.0733089447021484] [Train Accuracy: 0.9755503535270691]\n",
            "[Validation Loss: 1.0011329650878906] [Validation Accuracy: 0.9922583103179932]\n",
            "Early Stop Count: 0\n",
            "\n",
            "---------- KFold[2/5] ----------\n",
            "      ** Save Model **\n",
            "[Epoch 1/5] [elapsed time: 1098.3929207324982]\n",
            "[Train Loss: 3.5633392333984375] [Train Accuracy: 0.32349807024002075]\n",
            "[Validation Loss: 1.839813232421875] [Validation Accuracy: 0.7579074501991272]\n",
            "Early Stop Count: 0\n",
            "\n",
            "      ** Save Model **\n",
            "[Epoch 2/5] [elapsed time: 2194.6618790626526]\n",
            "[Train Loss: 1.4590263366699219] [Train Accuracy: 0.8707545399665833]\n",
            "[Validation Loss: 1.0920486450195312] [Validation Accuracy: 0.9817936420440674]\n",
            "Early Stop Count: 0\n",
            "\n",
            "      ** Save Model **\n",
            "[Epoch 3/5] [elapsed time: 3291.892402410507]\n",
            "[Train Loss: 1.160501480102539] [Train Accuracy: 0.9557847380638123]\n",
            "[Validation Loss: 1.0300712585449219] [Validation Accuracy: 0.9891788959503174]\n",
            "Early Stop Count: 0\n",
            "\n",
            "      ** Save Model **\n",
            "[Epoch 4/5] [elapsed time: 4389.781682729721]\n",
            "[Train Loss: 1.0995769500732422] [Train Accuracy: 0.9689096212387085]\n",
            "[Validation Loss: 0.9944381713867188] [Validation Accuracy: 0.991943359375]\n",
            "Early Stop Count: 0\n",
            "\n",
            "[Epoch 5/5] [elapsed time: 5487.662286996841]\n",
            "[Train Loss: 1.0781116485595703] [Train Accuracy: 0.9744920134544373]\n",
            "[Validation Loss: 1.0016059875488281] [Validation Accuracy: 0.9921875]\n",
            "Early Stop Count: 1\n",
            "\n",
            "---------- KFold[3/5] ----------\n",
            "      ** Save Model **\n",
            "[Epoch 1/5] [elapsed time: 1100.250521659851]\n",
            "[Train Loss: 3.5847434997558594] [Train Accuracy: 0.3181774318218231]\n",
            "[Validation Loss: 1.847259521484375] [Validation Accuracy: 0.7633679509162903]\n",
            "Early Stop Count: 0\n",
            "\n",
            "      ** Save Model **\n",
            "[Epoch 2/5] [elapsed time: 2199.472398042679]\n",
            "[Train Loss: 1.4728469848632812] [Train Accuracy: 0.8665642142295837]\n",
            "[Validation Loss: 1.0945358276367188] [Validation Accuracy: 0.9791944026947021]\n",
            "Early Stop Count: 0\n",
            "\n",
            "      ** Save Model **\n",
            "[Epoch 3/5] [elapsed time: 3297.0298664569855]\n",
            "[Train Loss: 1.1534805297851562] [Train Accuracy: 0.9572929739952087]\n",
            "[Validation Loss: 1.0377655029296875] [Validation Accuracy: 0.98779296875]\n",
            "Early Stop Count: 0\n",
            "\n",
            "      ** Save Model **\n",
            "[Epoch 4/5] [elapsed time: 4397.0246686935425]\n",
            "[Train Loss: 1.1154613494873047] [Train Accuracy: 0.9650163054466248]\n",
            "[Validation Loss: 1.0124893188476562] [Validation Accuracy: 0.99163818359375]\n",
            "Early Stop Count: 0\n",
            "\n",
            "      ** Save Model **\n",
            "[Epoch 5/5] [elapsed time: 5496.542724370956]\n",
            "[Train Loss: 1.0800657272338867] [Train Accuracy: 0.9739097952842712]\n",
            "[Validation Loss: 0.9870719909667969] [Validation Accuracy: 0.99249267578125]\n",
            "Early Stop Count: 0\n",
            "\n",
            "---------- KFold[4/5] ----------\n",
            "      ** Save Model **\n",
            "[Epoch 1/5] [elapsed time: 1098.479485988617]\n",
            "[Train Loss: 3.5845890045166016] [Train Accuracy: 0.3200214207172394]\n",
            "[Validation Loss: 1.7972564697265625] [Validation Accuracy: 0.7661009430885315]\n",
            "Early Stop Count: 0\n",
            "\n",
            "      ** Save Model **\n",
            "[Epoch 2/5] [elapsed time: 2196.0643565654755]\n",
            "[Train Loss: 1.4653148651123047] [Train Accuracy: 0.8697298765182495]\n",
            "[Validation Loss: 1.1025543212890625] [Validation Accuracy: 0.9774065017700195]\n",
            "Early Stop Count: 0\n",
            "\n",
            "      ** Save Model **\n",
            "[Epoch 3/5] [elapsed time: 3291.768229484558]\n",
            "[Train Loss: 1.1727046966552734] [Train Accuracy: 0.951507568359375]\n",
            "[Validation Loss: 1.0197944641113281] [Validation Accuracy: 0.9892830848693848]\n",
            "Early Stop Count: 0\n",
            "\n",
            "      ** Save Model **\n",
            "[Epoch 4/5] [elapsed time: 4387.126626968384]\n",
            "[Train Loss: 1.093994140625] [Train Accuracy: 0.9706467986106873]\n",
            "[Validation Loss: 1.0030555725097656] [Validation Accuracy: 0.9922127723693848]\n",
            "Early Stop Count: 0\n",
            "\n",
            "      ** Save Model **\n",
            "[Epoch 5/5] [elapsed time: 5481.765357255936]\n",
            "[Train Loss: 1.0733795166015625] [Train Accuracy: 0.9743417501449585]\n",
            "[Validation Loss: 0.99169921875] [Validation Accuracy: 0.99298095703125]\n",
            "Early Stop Count: 0\n",
            "\n",
            "---------- KFold[5/5] ----------\n",
            "      ** Save Model **\n",
            "[Epoch 1/5] [elapsed time: 1096.5436708927155]\n",
            "[Train Loss: 3.525388717651367] [Train Accuracy: 0.3358600437641144]\n",
            "[Validation Loss: 1.757171630859375] [Validation Accuracy: 0.7778554558753967]\n",
            "Early Stop Count: 0\n",
            "\n",
            "      ** Save Model **\n",
            "[Epoch 2/5] [elapsed time: 2190.9410314559937]\n",
            "[Train Loss: 1.4591026306152344] [Train Accuracy: 0.8721947073936462]\n",
            "[Validation Loss: 1.0982894897460938] [Validation Accuracy: 0.9780526161193848]\n",
            "Early Stop Count: 0\n",
            "\n",
            "      ** Save Model **\n",
            "[Epoch 3/5] [elapsed time: 3290.270695924759]\n",
            "[Train Loss: 1.1651592254638672] [Train Accuracy: 0.9543327689170837]\n",
            "[Validation Loss: 1.0269546508789062] [Validation Accuracy: 0.9891610145568848]\n",
            "Early Stop Count: 0\n",
            "\n",
            "      ** Save Model **\n",
            "[Epoch 4/5] [elapsed time: 4388.4637150764465]\n",
            "[Train Loss: 1.0985832214355469] [Train Accuracy: 0.9692100882530212]\n",
            "[Validation Loss: 0.9982490539550781] [Validation Accuracy: 0.9922306537628174]\n",
            "Early Stop Count: 0\n",
            "\n",
            "[Epoch 5/5] [elapsed time: 5487.687306165695]\n",
            "[Train Loss: 1.0685157775878906] [Train Accuracy: 0.9756492972373962]\n",
            "[Validation Loss: 1.0030975341796875] [Validation Accuracy: 0.9908268451690674]\n",
            "Early Stop Count: 1\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DThXjULSa9_D",
        "outputId": "7237d653-448f-4dab-979a-07318b8958dd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['save_models/best_model_1fold_epoch-5.pth',\n",
              " 'save_models/best_model_2fold_epoch-4.pth',\n",
              " 'save_models/best_model_3fold_epoch-5.pth',\n",
              " 'save_models/best_model_4fold_epoch-5.pth',\n",
              " 'save_models/best_model_5fold_epoch-4.pth']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = CustomDataset(test_image_paths, mode='test')\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "UsLgNgT2VMQC"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_list = []\n",
        "with torch.no_grad():\n",
        "    for imgs in test_loader:\n",
        "        imgs = imgs.to(device)\n",
        "        preds = 0\n",
        "        for model_path in models:\n",
        "            model = Model(n_classes).to(device)\n",
        "            model.load_state_dict(torch.load(model_path))\n",
        "\n",
        "            outputs = model(imgs)\n",
        "            preds += outputs\n",
        "\n",
        "        preds /= len(models)\n",
        "        preds = F.softmax(preds, -1)\n",
        "        preds_list.extend(preds.detach().cpu().numpy())"
      ],
      "metadata": {
        "id": "vPTtb5hrRe6M"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(preds_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mX-7lhsKL1u",
        "outputId": "5e50c689-25bd-4f2b-8b05-7be537b24c56"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10357"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.read_csv('sample_submission.csv')\n",
        "id = submission.id.values\n",
        "\n",
        "preds_list = np.array(preds_list)\n",
        "id = np.expand_dims(np.array(id), 1)\n",
        "data = np.concatenate([id, preds_list], 1)\n",
        "\n",
        "new_sub = pd.DataFrame(data = data, columns = submission.columns)\n",
        "new_sub.reset_index()\n",
        "new_sub.to_csv('cls_submission.csv', index=False)"
      ],
      "metadata": {
        "id": "VlcoFoz4r0Wd"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_sub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "5ThIwsOwyxSh",
        "outputId": "4a32fe16-6494-4c7b-85a6-b80dcdc16ad6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                     id affenpinscher afghan_hound  \\\n",
              "0      000621fb3cbb32d8935728e48679680e      0.011623     0.017176   \n",
              "1      00102ee9d8eb90812350685311fe5890      0.006032     0.009808   \n",
              "2      0012a730dfa437f5f3613fb75efcd4ce      0.020832     0.004795   \n",
              "3      001510bc8570bbeee98c8d80c8a95ec1      0.010368     0.003696   \n",
              "4      001a5f3114548acdefa3d4da05474c2e      0.005868     0.003424   \n",
              "...                                 ...           ...          ...   \n",
              "10352  ffeda8623d4eee33c6d1156a2ecbfcf8      0.001881     0.010561   \n",
              "10353  fff1ec9e6e413275984966f745a313b0      0.001494     0.008583   \n",
              "10354  fff74b59b758bbbf13a5793182a9bbe4      0.012315     0.001434   \n",
              "10355  fff7d50d848e8014ac1e9172dc6762a3      0.001412     0.001159   \n",
              "10356  fffbff22c1f51e3dc80c4bf04089545b      0.009572     0.002136   \n",
              "\n",
              "      african_hunting_dog  airedale american_staffordshire_terrier  \\\n",
              "0                0.002569  0.005146                       0.005761   \n",
              "1                0.001823  0.007684                       0.005053   \n",
              "2                0.001641  0.003896                       0.003626   \n",
              "3                0.004707  0.009154                       0.007875   \n",
              "4                0.006845  0.005653                       0.013286   \n",
              "...                   ...       ...                            ...   \n",
              "10352            0.006832  0.006786                       0.002862   \n",
              "10353            0.012453  0.015297                       0.005231   \n",
              "10354            0.007721  0.025982                       0.002881   \n",
              "10355            0.014811  0.005997                       0.024808   \n",
              "10356            0.002528  0.002292                       0.003666   \n",
              "\n",
              "      appenzeller australian_terrier   basenji    basset  ... toy_poodle  \\\n",
              "0        0.002292           0.011738  0.008592  0.002855  ...   0.009848   \n",
              "1        0.001485           0.002297  0.003839  0.004334  ...   0.015877   \n",
              "2        0.003653           0.000559  0.002871  0.001199  ...    0.01005   \n",
              "3        0.006757           0.005671  0.006547  0.013764  ...   0.012393   \n",
              "4        0.003132           0.003156  0.003872  0.005182  ...   0.005426   \n",
              "...           ...                ...       ...       ...  ...        ...   \n",
              "10352    0.001559           0.014651   0.00989  0.011766  ...   0.005387   \n",
              "10353     0.01076            0.00107  0.025973  0.002863  ...   0.000601   \n",
              "10354    0.019275           0.001568  0.002108  0.006215  ...   0.017571   \n",
              "10355    0.001302           0.001584  0.009992   0.00694  ...   0.014779   \n",
              "10356     0.00194           0.005878  0.006766  0.000974  ...   0.001689   \n",
              "\n",
              "      toy_terrier    vizsla walker_hound weimaraner welsh_springer_spaniel  \\\n",
              "0         0.01745  0.001263     0.008681    0.00096               0.018472   \n",
              "1        0.003149   0.00553     0.014287   0.006413               0.006463   \n",
              "2        0.006658  0.009073     0.004295   0.008811                0.00492   \n",
              "3        0.003447  0.008222     0.006696   0.002819               0.010323   \n",
              "4        0.028806  0.009193     0.006664   0.045173                0.00274   \n",
              "...           ...       ...          ...        ...                    ...   \n",
              "10352    0.009863  0.002226     0.001622   0.005036               0.004545   \n",
              "10353    0.002091  0.001037     0.005391   0.006843               0.006286   \n",
              "10354     0.00897  0.017216     0.028656   0.003458               0.005134   \n",
              "10355    0.002449  0.007192     0.002207   0.004831               0.005263   \n",
              "10356     0.00305  0.002103      0.00914   0.004005               0.005927   \n",
              "\n",
              "      west_highland_white_terrier   whippet wire-haired_fox_terrier  \\\n",
              "0                         0.00343  0.005553                0.008905   \n",
              "1                         0.00432  0.013286                 0.00203   \n",
              "2                        0.009782  0.004299                0.013971   \n",
              "3                        0.008404  0.010792                0.009483   \n",
              "4                        0.007434  0.003926                0.005949   \n",
              "...                           ...       ...                     ...   \n",
              "10352                    0.013655   0.00961                0.004165   \n",
              "10353                    0.001779  0.003186                0.002002   \n",
              "10354                    0.007319  0.003541                 0.02144   \n",
              "10355                    0.003097  0.002629                0.045951   \n",
              "10356                    0.007363  0.011414                0.050194   \n",
              "\n",
              "      yorkshire_terrier  \n",
              "0              0.003025  \n",
              "1              0.003148  \n",
              "2              0.004048  \n",
              "3              0.004091  \n",
              "4              0.002979  \n",
              "...                 ...  \n",
              "10352          0.002698  \n",
              "10353          0.003152  \n",
              "10354          0.014716  \n",
              "10355          0.002255  \n",
              "10356          0.022214  \n",
              "\n",
              "[10357 rows x 121 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-72557958-3ca6-4886-8027-3a7df0c5b339\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>affenpinscher</th>\n",
              "      <th>afghan_hound</th>\n",
              "      <th>african_hunting_dog</th>\n",
              "      <th>airedale</th>\n",
              "      <th>american_staffordshire_terrier</th>\n",
              "      <th>appenzeller</th>\n",
              "      <th>australian_terrier</th>\n",
              "      <th>basenji</th>\n",
              "      <th>basset</th>\n",
              "      <th>...</th>\n",
              "      <th>toy_poodle</th>\n",
              "      <th>toy_terrier</th>\n",
              "      <th>vizsla</th>\n",
              "      <th>walker_hound</th>\n",
              "      <th>weimaraner</th>\n",
              "      <th>welsh_springer_spaniel</th>\n",
              "      <th>west_highland_white_terrier</th>\n",
              "      <th>whippet</th>\n",
              "      <th>wire-haired_fox_terrier</th>\n",
              "      <th>yorkshire_terrier</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000621fb3cbb32d8935728e48679680e</td>\n",
              "      <td>0.011623</td>\n",
              "      <td>0.017176</td>\n",
              "      <td>0.002569</td>\n",
              "      <td>0.005146</td>\n",
              "      <td>0.005761</td>\n",
              "      <td>0.002292</td>\n",
              "      <td>0.011738</td>\n",
              "      <td>0.008592</td>\n",
              "      <td>0.002855</td>\n",
              "      <td>...</td>\n",
              "      <td>0.009848</td>\n",
              "      <td>0.01745</td>\n",
              "      <td>0.001263</td>\n",
              "      <td>0.008681</td>\n",
              "      <td>0.00096</td>\n",
              "      <td>0.018472</td>\n",
              "      <td>0.00343</td>\n",
              "      <td>0.005553</td>\n",
              "      <td>0.008905</td>\n",
              "      <td>0.003025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00102ee9d8eb90812350685311fe5890</td>\n",
              "      <td>0.006032</td>\n",
              "      <td>0.009808</td>\n",
              "      <td>0.001823</td>\n",
              "      <td>0.007684</td>\n",
              "      <td>0.005053</td>\n",
              "      <td>0.001485</td>\n",
              "      <td>0.002297</td>\n",
              "      <td>0.003839</td>\n",
              "      <td>0.004334</td>\n",
              "      <td>...</td>\n",
              "      <td>0.015877</td>\n",
              "      <td>0.003149</td>\n",
              "      <td>0.00553</td>\n",
              "      <td>0.014287</td>\n",
              "      <td>0.006413</td>\n",
              "      <td>0.006463</td>\n",
              "      <td>0.00432</td>\n",
              "      <td>0.013286</td>\n",
              "      <td>0.00203</td>\n",
              "      <td>0.003148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0012a730dfa437f5f3613fb75efcd4ce</td>\n",
              "      <td>0.020832</td>\n",
              "      <td>0.004795</td>\n",
              "      <td>0.001641</td>\n",
              "      <td>0.003896</td>\n",
              "      <td>0.003626</td>\n",
              "      <td>0.003653</td>\n",
              "      <td>0.000559</td>\n",
              "      <td>0.002871</td>\n",
              "      <td>0.001199</td>\n",
              "      <td>...</td>\n",
              "      <td>0.01005</td>\n",
              "      <td>0.006658</td>\n",
              "      <td>0.009073</td>\n",
              "      <td>0.004295</td>\n",
              "      <td>0.008811</td>\n",
              "      <td>0.00492</td>\n",
              "      <td>0.009782</td>\n",
              "      <td>0.004299</td>\n",
              "      <td>0.013971</td>\n",
              "      <td>0.004048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>001510bc8570bbeee98c8d80c8a95ec1</td>\n",
              "      <td>0.010368</td>\n",
              "      <td>0.003696</td>\n",
              "      <td>0.004707</td>\n",
              "      <td>0.009154</td>\n",
              "      <td>0.007875</td>\n",
              "      <td>0.006757</td>\n",
              "      <td>0.005671</td>\n",
              "      <td>0.006547</td>\n",
              "      <td>0.013764</td>\n",
              "      <td>...</td>\n",
              "      <td>0.012393</td>\n",
              "      <td>0.003447</td>\n",
              "      <td>0.008222</td>\n",
              "      <td>0.006696</td>\n",
              "      <td>0.002819</td>\n",
              "      <td>0.010323</td>\n",
              "      <td>0.008404</td>\n",
              "      <td>0.010792</td>\n",
              "      <td>0.009483</td>\n",
              "      <td>0.004091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>001a5f3114548acdefa3d4da05474c2e</td>\n",
              "      <td>0.005868</td>\n",
              "      <td>0.003424</td>\n",
              "      <td>0.006845</td>\n",
              "      <td>0.005653</td>\n",
              "      <td>0.013286</td>\n",
              "      <td>0.003132</td>\n",
              "      <td>0.003156</td>\n",
              "      <td>0.003872</td>\n",
              "      <td>0.005182</td>\n",
              "      <td>...</td>\n",
              "      <td>0.005426</td>\n",
              "      <td>0.028806</td>\n",
              "      <td>0.009193</td>\n",
              "      <td>0.006664</td>\n",
              "      <td>0.045173</td>\n",
              "      <td>0.00274</td>\n",
              "      <td>0.007434</td>\n",
              "      <td>0.003926</td>\n",
              "      <td>0.005949</td>\n",
              "      <td>0.002979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10352</th>\n",
              "      <td>ffeda8623d4eee33c6d1156a2ecbfcf8</td>\n",
              "      <td>0.001881</td>\n",
              "      <td>0.010561</td>\n",
              "      <td>0.006832</td>\n",
              "      <td>0.006786</td>\n",
              "      <td>0.002862</td>\n",
              "      <td>0.001559</td>\n",
              "      <td>0.014651</td>\n",
              "      <td>0.00989</td>\n",
              "      <td>0.011766</td>\n",
              "      <td>...</td>\n",
              "      <td>0.005387</td>\n",
              "      <td>0.009863</td>\n",
              "      <td>0.002226</td>\n",
              "      <td>0.001622</td>\n",
              "      <td>0.005036</td>\n",
              "      <td>0.004545</td>\n",
              "      <td>0.013655</td>\n",
              "      <td>0.00961</td>\n",
              "      <td>0.004165</td>\n",
              "      <td>0.002698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10353</th>\n",
              "      <td>fff1ec9e6e413275984966f745a313b0</td>\n",
              "      <td>0.001494</td>\n",
              "      <td>0.008583</td>\n",
              "      <td>0.012453</td>\n",
              "      <td>0.015297</td>\n",
              "      <td>0.005231</td>\n",
              "      <td>0.01076</td>\n",
              "      <td>0.00107</td>\n",
              "      <td>0.025973</td>\n",
              "      <td>0.002863</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000601</td>\n",
              "      <td>0.002091</td>\n",
              "      <td>0.001037</td>\n",
              "      <td>0.005391</td>\n",
              "      <td>0.006843</td>\n",
              "      <td>0.006286</td>\n",
              "      <td>0.001779</td>\n",
              "      <td>0.003186</td>\n",
              "      <td>0.002002</td>\n",
              "      <td>0.003152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10354</th>\n",
              "      <td>fff74b59b758bbbf13a5793182a9bbe4</td>\n",
              "      <td>0.012315</td>\n",
              "      <td>0.001434</td>\n",
              "      <td>0.007721</td>\n",
              "      <td>0.025982</td>\n",
              "      <td>0.002881</td>\n",
              "      <td>0.019275</td>\n",
              "      <td>0.001568</td>\n",
              "      <td>0.002108</td>\n",
              "      <td>0.006215</td>\n",
              "      <td>...</td>\n",
              "      <td>0.017571</td>\n",
              "      <td>0.00897</td>\n",
              "      <td>0.017216</td>\n",
              "      <td>0.028656</td>\n",
              "      <td>0.003458</td>\n",
              "      <td>0.005134</td>\n",
              "      <td>0.007319</td>\n",
              "      <td>0.003541</td>\n",
              "      <td>0.02144</td>\n",
              "      <td>0.014716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10355</th>\n",
              "      <td>fff7d50d848e8014ac1e9172dc6762a3</td>\n",
              "      <td>0.001412</td>\n",
              "      <td>0.001159</td>\n",
              "      <td>0.014811</td>\n",
              "      <td>0.005997</td>\n",
              "      <td>0.024808</td>\n",
              "      <td>0.001302</td>\n",
              "      <td>0.001584</td>\n",
              "      <td>0.009992</td>\n",
              "      <td>0.00694</td>\n",
              "      <td>...</td>\n",
              "      <td>0.014779</td>\n",
              "      <td>0.002449</td>\n",
              "      <td>0.007192</td>\n",
              "      <td>0.002207</td>\n",
              "      <td>0.004831</td>\n",
              "      <td>0.005263</td>\n",
              "      <td>0.003097</td>\n",
              "      <td>0.002629</td>\n",
              "      <td>0.045951</td>\n",
              "      <td>0.002255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10356</th>\n",
              "      <td>fffbff22c1f51e3dc80c4bf04089545b</td>\n",
              "      <td>0.009572</td>\n",
              "      <td>0.002136</td>\n",
              "      <td>0.002528</td>\n",
              "      <td>0.002292</td>\n",
              "      <td>0.003666</td>\n",
              "      <td>0.00194</td>\n",
              "      <td>0.005878</td>\n",
              "      <td>0.006766</td>\n",
              "      <td>0.000974</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001689</td>\n",
              "      <td>0.00305</td>\n",
              "      <td>0.002103</td>\n",
              "      <td>0.00914</td>\n",
              "      <td>0.004005</td>\n",
              "      <td>0.005927</td>\n",
              "      <td>0.007363</td>\n",
              "      <td>0.011414</td>\n",
              "      <td>0.050194</td>\n",
              "      <td>0.022214</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10357 rows × 121 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-72557958-3ca6-4886-8027-3a7df0c5b339')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-72557958-3ca6-4886-8027-3a7df0c5b339 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-72557958-3ca6-4886-8027-3a7df0c5b339');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    }
  ]
}